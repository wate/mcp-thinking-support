"""ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°æ”¯æ´ãƒ„ãƒ¼ãƒ«"""

from datetime import datetime
from typing import Dict, List, Optional
from enum import Enum


class BiasType(Enum):
    """èªçŸ¥ãƒã‚¤ã‚¢ã‚¹ã®ç¨®é¡"""
    CONFIRMATION = "ç¢ºè¨¼ãƒã‚¤ã‚¢ã‚¹"
    AVAILABILITY = "åˆ©ç”¨å¯èƒ½æ€§ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯"
    ANCHORING = "ã‚¢ãƒ³ã‚«ãƒªãƒ³ã‚°åŠ¹æœ"
    BANDWAGON = "ãƒãƒ³ãƒ‰ãƒ¯ã‚´ãƒ³åŠ¹æœ" 
    AUTHORITY = "æ¨©å¨ã¸ã®è¨´ãˆ"
    AD_HOMINEM = "äººèº«æ”»æ’ƒ"
    STRAW_MAN = "ã‚ã‚‰äººå½¢è«–æ³•"
    FALSE_DILEMMA = "å½ã®äºŒåˆ†æ³•"
    SLIPPERY_SLOPE = "æ»‘ã‚Šã‚„ã™ã„å‚è«–æ³•"
    HASTY_GENERALIZATION = "æ—©ã¾ã£ãŸä¸€èˆ¬åŒ–"


class ReliabilityLevel(Enum):
    """ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«"""
    HIGH = "é«˜ã„"
    MEDIUM = "ä¸­ç¨‹åº¦"  
    LOW = "ä½ã„"
    UNKNOWN = "ä¸æ˜"


class SourceType(Enum):
    """æƒ…å ±æºã®ç¨®é¡"""
    ACADEMIC = "å­¦è¡“è«–æ–‡"
    NEWS_MEDIA = "å ±é“æ©Ÿé–¢"
    SOCIAL_MEDIA = "ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢"
    PERSONAL_BLOG = "å€‹äººãƒ–ãƒ­ã‚°"
    GOVERNMENT = "æ”¿åºœæ©Ÿé–¢"
    CORPORATE = "ä¼æ¥­"
    UNKNOWN = "ä¸æ˜"


class ClaimAnalysis:
    """ä¸»å¼µåˆ†æã®çµæœã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, claim: str, source: Optional[str] = None):
        self.claim = claim
        self.source = source
        self.reliability_level = ReliabilityLevel.UNKNOWN
        self.source_type = SourceType.UNKNOWN
        self.strengths: List[str] = []
        self.weaknesses: List[str] = []
        self.questions_to_consider: List[str] = []
        self.supporting_evidence: List[str] = []
        self.contradicting_evidence: List[str] = []
        self.analyzed_at = datetime.now()


class BiasAnalysis:
    """åè¦‹åˆ†æã®çµæœã‚’è¡¨ã™ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, content: str):
        self.content = content
        self.identified_biases: List[BiasType] = []
        self.bias_explanations: Dict[BiasType, str] = {}
        self.logical_fallacies: List[str] = []
        self.recommendations: List[str] = []
        self.analyzed_at = datetime.now()


class CriticalThinking:
    """ã‚¯ãƒªãƒ†ã‚£ã‚«ãƒ«ã‚·ãƒ³ã‚­ãƒ³ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.analyses: Dict[str, ClaimAnalysis] = {}
        self.bias_analyses: Dict[str, BiasAnalysis] = {}
    
    async def analyze_claim(self, claim: str, source: Optional[str] = None) -> str:
        """ä¸»å¼µã‚„æƒ…å ±ã‚’æ‰¹åˆ¤çš„ã«åˆ†æã—ã€ä¿¡é ¼æ€§ã‚’è©•ä¾¡ã™ã‚‹"""
        
        analysis = ClaimAnalysis(claim, source)
        
        # æƒ…å ±æºã®ç¨®é¡ã‚’æ¨å®š
        analysis.source_type = self._classify_source(source)
        
        # ä¸»å¼µã‚’åˆ†æ
        self._analyze_claim_content(analysis)
        
        # ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’åˆ¤å®š
        analysis.reliability_level = self._assess_reliability(analysis)
        
        # åˆ†æçµæœã‚’ä¿å­˜
        analysis_id = str(len(self.analyses) + 1)
        self.analyses[analysis_id] = analysis
        
        # çµæœã‚’æ•´å½¢ã—ã¦è¿”ã™
        result = f"æ‰¹åˆ¤çš„åˆ†æçµæœ (ID: {analysis_id})\n\n"
        result += f"åˆ†æå¯¾è±¡: {claim}\n"
        if source:
            result += f"æƒ…å ±æº: {source}\n"
        result += f"æƒ…å ±æºã‚¿ã‚¤ãƒ—: {analysis.source_type.value}\n"
        result += f"ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«: {analysis.reliability_level.value}\n\n"
        
        if analysis.strengths:
            result += "å¼·ã¿ãƒ»æ ¹æ‹ :\n"
            for strength in analysis.strengths:
                result += f"â€¢ {strength}\n"
            result += "\n"
        
        if analysis.weaknesses:
            result += "å¼±ç‚¹ãƒ»ç–‘å•ç‚¹:\n"
            for weakness in analysis.weaknesses:
                result += f"â€¢ {weakness}\n"
            result += "\n"
        
        if analysis.questions_to_consider:
            result += "æ¤œè¨ã™ã¹ãè³ªå•:\n"
            for question in analysis.questions_to_consider:
                result += f"â“ {question}\n"
            result += "\n"
        
        result += "ğŸ’¡ æ‰¹åˆ¤çš„æ€è€ƒã®ãƒã‚¤ãƒ³ãƒˆ:\n"
        result += "â€¢ è¤‡æ•°ã®æƒ…å ±æºã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹\n"
        result += "â€¢ åå¯¾æ„è¦‹ã‚‚æ¢ã—ã¦æ¤œè¨ã™ã‚‹\n"  
        result += "â€¢ ä¸»å¼µã®æ ¹æ‹ ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„è¨¼æ‹ ã‚’ç¢ºèªã™ã‚‹\n"
        result += "â€¢ æƒ…å ±æä¾›è€…ã®å‹•æ©Ÿã‚„åˆ©å®³é–¢ä¿‚ã‚’è€ƒæ…®ã™ã‚‹"
        
        return result
    
    async def identify_bias(self, content: str) -> str:
        """æƒ…å ±ã‚„è­°è«–ã«ãŠã‘ã‚‹åè¦‹ã‚„è«–ç†çš„èª¤è¬¬ã‚’ç‰¹å®šã™ã‚‹"""
        
        analysis = BiasAnalysis(content)
        
        # ãƒã‚¤ã‚¢ã‚¹ã¨è«–ç†çš„èª¤è¬¬ã‚’ç‰¹å®š
        self._identify_biases(analysis)
        self._identify_logical_fallacies(analysis)
        
        # æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
        self._generate_recommendations(analysis)
        
        # åˆ†æçµæœã‚’ä¿å­˜
        analysis_id = str(len(self.bias_analyses) + 1)
        self.bias_analyses[analysis_id] = analysis
        
        # çµæœã‚’æ•´å½¢ã—ã¦è¿”ã™
        result = f"ãƒã‚¤ã‚¢ã‚¹ãƒ»èª¤è¬¬åˆ†æçµæœ (ID: {analysis_id})\n\n"
        
        if analysis.identified_biases:
            result += "ç‰¹å®šã•ã‚ŒãŸãƒã‚¤ã‚¢ã‚¹:\n"
            for bias in analysis.identified_biases:
                result += f"ğŸ§  {bias.value}\n"
                if bias in analysis.bias_explanations:
                    result += f"   èª¬æ˜: {analysis.bias_explanations[bias]}\n"
            result += "\n"
        
        if analysis.logical_fallacies:
            result += "è«–ç†çš„èª¤è¬¬:\n"
            for fallacy in analysis.logical_fallacies:
                result += f"âš ï¸ {fallacy}\n" 
            result += "\n"
        
        if analysis.recommendations:
            result += "æ”¹å–„ææ¡ˆ:\n"
            for rec in analysis.recommendations:
                result += f"ğŸ’¡ {rec}\n"
            result += "\n"
        
        if not analysis.identified_biases and not analysis.logical_fallacies:
            result += "âœ… æ˜ç¢ºãªãƒã‚¤ã‚¢ã‚¹ã‚„è«–ç†çš„èª¤è¬¬ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚\n\n"
        
        result += "ğŸ“š æ‰¹åˆ¤çš„æ€è€ƒã®ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆ:\n"
        result += "â€¢ æ„Ÿæƒ…çš„ãªè¨€è‘‰é£ã„ã«æ³¨æ„ã™ã‚‹\n"
        result += "â€¢ ä¸€èˆ¬åŒ–ã‚„æ¥µç«¯ãªè¡¨ç¾ã‚’é¿ã‘ã‚‹\n"
        result += "â€¢ å¤šè§’çš„ãªè¦–ç‚¹ã‹ã‚‰ç‰©äº‹ã‚’è€ƒãˆã‚‹\n"
        result += "â€¢ æ ¹æ‹ ã®ãªã„æ¨æ¸¬ã¨äº‹å®Ÿã‚’åŒºåˆ¥ã™ã‚‹"
        
        return result
    
    def _classify_source(self, source: Optional[str]) -> SourceType:
        """æƒ…å ±æºã®ç¨®é¡ã‚’åˆ†é¡ã™ã‚‹"""
        if not source:
            return SourceType.UNKNOWN
        
        source_lower = source.lower()
        
        if any(domain in source_lower for domain in ['ac.jp', 'edu', 'arxiv', 'pubmed']):
            return SourceType.ACADEMIC
        elif any(domain in source_lower for domain in ['twitter', 'facebook', 'instagram']):
            return SourceType.SOCIAL_MEDIA
        elif any(domain in source_lower for domain in ['gov', 'çœ', 'åº']):
            return SourceType.GOVERNMENT
        elif any(word in source_lower for word in ['news', 'times', 'post', 'æ–°è']):
            return SourceType.NEWS_MEDIA
        elif any(word in source_lower for word in ['blog', 'note', 'qiita']):
            return SourceType.PERSONAL_BLOG
        else:
            return SourceType.CORPORATE
    
    def _analyze_claim_content(self, analysis: ClaimAnalysis):
        """ä¸»å¼µã®å†…å®¹ã‚’åˆ†æã™ã‚‹"""
        claim = analysis.claim.lower()
        
        # å¼·ã¿ãƒ»æ ¹æ‹ ã‚’ç‰¹å®š
        if "ç ”ç©¶" in claim or "ãƒ‡ãƒ¼ã‚¿" in claim or "çµ±è¨ˆ" in claim:
            analysis.strengths.append("ç ”ç©¶ã‚„ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã„ã‚‹å¯èƒ½æ€§")
        if "å°‚é–€å®¶" in claim or "æ•™æˆ" in claim:
            analysis.strengths.append("å°‚é–€å®¶ã®æ„è¦‹ã¨ã—ã¦æç¤ºã•ã‚Œã¦ã„ã‚‹")
        
        # å¼±ç‚¹ãƒ»ç–‘å•ç‚¹ã‚’ç‰¹å®š  
        if "ã¿ã‚“ãª" in claim or "èª°ã§ã‚‚" in claim or "å¸¸ã«" in claim:
            analysis.weaknesses.append("éåº¦ãªä¸€èˆ¬åŒ–ã®å¯èƒ½æ€§")
        if "çµ¶å¯¾" in claim or "é–“é•ã„ãªã" in claim:
            analysis.weaknesses.append("æ–­å®šçš„ã™ãã‚‹è¡¨ç¾")
        if "ã¨æ€ã†" in claim or "ã¨æ„Ÿã˜ã‚‹" in claim:
            analysis.weaknesses.append("ä¸»è¦³çš„ãªæ„è¦‹ã«åŸºã¥ã„ã¦ã„ã‚‹")
        
        # æ¤œè¨ã™ã¹ãè³ªå•ã‚’ç”Ÿæˆ
        analysis.questions_to_consider.extend([
            "ã“ã®ä¸»å¼µã®æ ¹æ‹ ã¨ãªã‚‹ãƒ‡ãƒ¼ã‚¿ã‚„è¨¼æ‹ ã¯ä½•ã‹ï¼Ÿ",
            "åå¯¾æ„è¦‹ã‚„ç•°ãªã‚‹è§£é‡ˆã¯å­˜åœ¨ã™ã‚‹ã‹ï¼Ÿ", 
            "ä¸»å¼µè€…ã«ã¯ã©ã®ã‚ˆã†ãªèƒŒæ™¯ã‚„åˆ©å®³é–¢ä¿‚ãŒã‚ã‚‹ã‹ï¼Ÿ",
            "ã“ã®ä¸»å¼µã¯ä»–ã®ä¿¡é ¼ã§ãã‚‹æƒ…å ±æºã§ã‚‚ç¢ºèªã§ãã‚‹ã‹ï¼Ÿ"
        ])
    
    def _assess_reliability(self, analysis: ClaimAnalysis) -> ReliabilityLevel:
        """ä¿¡é ¼æ€§ãƒ¬ãƒ™ãƒ«ã‚’è©•ä¾¡ã™ã‚‹"""
        score = 0
        
        # æƒ…å ±æºã«ã‚ˆã‚‹è©•ä¾¡
        if analysis.source_type == SourceType.ACADEMIC:
            score += 3
        elif analysis.source_type == SourceType.GOVERNMENT:
            score += 2
        elif analysis.source_type == SourceType.NEWS_MEDIA:
            score += 1
        elif analysis.source_type == SourceType.SOCIAL_MEDIA:
            score -= 1
        
        # å¼·ã¿ãƒ»å¼±ç‚¹ã«ã‚ˆã‚‹è©•ä¾¡
        score += len(analysis.strengths)
        score -= len(analysis.weaknesses)
        
        if score >= 3:
            return ReliabilityLevel.HIGH
        elif score >= 1:
            return ReliabilityLevel.MEDIUM
        else:
            return ReliabilityLevel.LOW
    
    def _identify_biases(self, analysis: BiasAnalysis):
        """ãƒã‚¤ã‚¢ã‚¹ã‚’ç‰¹å®šã™ã‚‹"""
        content = analysis.content.lower()
        
        # ç¢ºè¨¼ãƒã‚¤ã‚¢ã‚¹
        if "ã‚„ã£ã±ã‚Š" in content or "å½“ç„¶" in content:
            analysis.identified_biases.append(BiasType.CONFIRMATION)
            analysis.bias_explanations[BiasType.CONFIRMATION] = "è‡ªåˆ†ã®ä¿¡å¿µã‚’æ”¯æŒã™ã‚‹æƒ…å ±ã®ã¿ã‚’é‡è¦–ã—ã¦ã„ã‚‹"
        
        # æ¨©å¨ã¸ã®è¨´ãˆ
        if "å°‚é–€å®¶ãŒè¨€ã†ã‹ã‚‰" in content or "æœ‰åäººãŒ" in content:
            analysis.identified_biases.append(BiasType.AUTHORITY)
            analysis.bias_explanations[BiasType.AUTHORITY] = "æ¨©å¨è€…ã®æ„è¦‹ã‚’ç„¡æ‰¹åˆ¤ã«å—ã‘å…¥ã‚Œã¦ã„ã‚‹"
        
        # ãƒãƒ³ãƒ‰ãƒ¯ã‚´ãƒ³åŠ¹æœ
        if "ã¿ã‚“ãªãŒ" in content or "æµè¡Œã‚Š" in content:
            analysis.identified_biases.append(BiasType.BANDWAGON)
            analysis.bias_explanations[BiasType.BANDWAGON] = "å¤šæ•°æ´¾ã®æ„è¦‹ã«åŒèª¿ã—ã¦ã„ã‚‹"
    
    def _identify_logical_fallacies(self, analysis: BiasAnalysis):
        """è«–ç†çš„èª¤è¬¬ã‚’ç‰¹å®šã™ã‚‹"""
        content = analysis.content.lower()
        
        if "aã‹bã‹ã—ã‹ãªã„" in content or "ç™½ã‹é»’ã‹" in content:
            analysis.logical_fallacies.append("å½ã®äºŒåˆ†æ³•: å®Ÿéš›ã«ã¯ã‚ˆã‚Šå¤šãã®é¸æŠè‚¢ãŒå­˜åœ¨ã™ã‚‹")
        
        if "ã ã‹ã‚‰" in content and "ã™ã¹ã¦" in content:
            analysis.logical_fallacies.append("æ—©ã¾ã£ãŸä¸€èˆ¬åŒ–: é™ã‚‰ã‚ŒãŸäº‹ä¾‹ã‹ã‚‰å…¨ä½“ã‚’åˆ¤æ–­ã—ã¦ã„ã‚‹")
    
    def _generate_recommendations(self, analysis: BiasAnalysis):
        """æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆã™ã‚‹"""
        if analysis.identified_biases or analysis.logical_fallacies:
            analysis.recommendations.extend([
                "åå¯¾æ„è¦‹ã‚‚ç©æ¥µçš„ã«æ¢ã—ã¦æ¤œè¨ã™ã‚‹",
                "è¤‡æ•°ã®æƒ…å ±æºã‹ã‚‰æƒ…å ±ã‚’åé›†ã™ã‚‹",
                "æ„Ÿæƒ…çš„ã«ãªã£ã¦ã„ã‚‹æ™‚ã¯åˆ¤æ–­ã‚’ä¿ç•™ã™ã‚‹",
                "çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ã‚„å®¢è¦³çš„è¨¼æ‹ ã‚’é‡è¦–ã™ã‚‹"
            ])
        else:
            analysis.recommendations.append("ç¾åœ¨ã®åˆ†æã¯æ¯”è¼ƒçš„ãƒãƒ©ãƒ³ã‚¹ãŒå–ã‚Œã¦ã„ã¾ã™")